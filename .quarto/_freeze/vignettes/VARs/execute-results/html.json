{
  "hash": "a42a54011a98da4b060edddc75a57309",
  "result": {
    "markdown": "---\ntitle: \"VARs (`deepvars`)\"\noutput: rmarkdown::html_vignette\nvignette: >\n  %\\VignetteIndexEntry{VARs (`deepvars`)}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n\n\n## Reduced-form VAR \n\nThe reduced-form VAR($p$) with $K$ variables and $p$ lags (with $m \\in [1,p]$) can be written as\n\n$$\n\\begin{aligned}\n&& y_t&=A_1 y_{t-1} + A_2 y_{t-2} + ... + A_p y_{t-p} + u_t \\\\\n\\end{aligned}\n$$\n\nwhere $y_{t-m}$ are $(K \\times 1)$ vectors , $A_m$ are $(K \\times K)$ matrices of coefficients and $u_t$ is a $(K \\times 1)$ vector of residuals. \n\n### Estimation of VARs \n\nThe reduced-from VAR can be estimated by least-squares. \n\n#### Least Squares\n\nWe can rewrite the reduced-form model as \n\n$$\n\\begin{aligned}\n&& Y&= Z A + U \\\\\n\\end{aligned}\n$$\n\nsuch that the OLS estimator is simply\n\n$$\n\\begin{aligned}\n&& \\hat{A}&= {(Z'Z)}^{-1}Z'Y  \\\\\n\\end{aligned}\n$$\n\nwhere $Y$, $Z$ and $\\hat{A}$ are of dimensions $(T \\times K)$, $(T \\times (Kp+1))$ and $((Kp+1) \\times K)$, respectively.  \n\n#### MLE\n\nEquivalently, we can estimate the VAR through *Maximum-Likelihood-Estimation* (MLE). Under the assumption that $y_t$ are jointly normal (since by assumption $u_t \\sim N(0, \\Sigma_u)$), we have for the distribution function:\n\n$$\n\\begin{aligned}\n&& f(y_t|y_{t-1},...,y_{t-p+1})&=\\left(\\frac{1}{2 \\pi} \\right)^{\\frac{k}{2}} det \\left( \\Sigma_u\\right)^{-\\frac{1}{2}}  exp \\left(-\\frac{1}{2} u_t'{\\Sigma_u}^{-1}u_t \\right)\\\\\n\\end{aligned}\n$$\n\n#### Estimation\n\nThe `VAR` function can be used to estimate the VAR by least-squares or MLE. All estimations are run on an example data set. \n\n::: {.cell}\n\n```\n#>       date        e     prod       rw    U\n#> 1: 1980.00 929.6105 405.3665 386.1361 7.53\n#> 2: 1980.25 929.8040 404.6398 388.1358 7.70\n#> 3: 1980.50 930.3184 403.8149 390.5401 7.47\n#> 4: 1980.75 931.4277 404.2158 393.9638 7.27\n#> 5: 1981.00 932.6620 405.0467 396.7647 7.37\n#> 6: 1981.25 933.5509 404.4167 400.0217 7.13\n```\n:::\n\nThe underlying time series in levels look non-stationary \n\n::: {.cell fig.dim=\"[7,4]\"}\n::: {.cell-output-display}\n![Time series in levels.](VARs_files/figure-html/levels-1.png){width=672}\n:::\n:::\n\n\n::: {.cell}\n\n:::\n\nBelow the model is estimated in levels using 3 lags firstly through least-squares and secondly through MLE. \n\n::: {.cell}\n\n```{.r .cell-code}\nvar_ls = vareg(dt, lags = lags, method = \"ols\")\nvar_mle = vareg(dt, lags = lags, method = \"mle\")\n```\n:::\n\n### Stability condition\n\nAbove all series entered the estimation in levels. This may cause the VAR to be non-stable if one or more series are non-stationary. We can test for the VAR's stability by checking if the eigenvalues of its companion-form matrix lie within the unit circle. If furthermore $u_t$ has time-invariant variance and its first two moments are bounded, then the VAR is stationary. \n\nThe `VAR_stable` function can be used to do this. Applying this function to the previously estimated VAR reveals that it is in fact not stable, so at least one of the underlying variables is non-stationary. \n\n::: {.cell}\n\n```{.r .cell-code}\ninvisible(VAR_stable(var_ls, verbose = F)$test_result)\n```\n:::\n\nStandard univariate tests (e.g. ADF) can be used to test individual series for non-stationarity. For simplicity, let us take first differences of all series, which upon visual inspection look stationary. \n\n::: {.cell fig.dim=\"[7,4]\"}\n::: {.cell-output-display}\n![Time series in differences.](VARs_files/figure-html/after-diff-1.png){width=672}\n:::\n:::\n\nRe-running the stability test with the transformed data shows that the var is now stable when using 3 lags:\n\n::: {.cell}\n\n```{.r .cell-code}\ninvisible(VAR_stable(vareg(dt, lag=3))$test_result)\n```\n:::\n\n\n### Lag-length selection\n\nFinally, let's turn to selecting the right lag length for our estimation. The most common way to select the lag-length is through information criteria, which can be down using the `VAR_lag_select` function.By default the maximum considered lag length is set to 10 and the Akaike Information Criterium is used. Applying the function to the data in differences yields\n\n::: {.cell}\n::: {.cell-output-display}\n|  m|        SIC|       HQC|       AIC|\n|--:|----------:|---------:|---------:|\n|  1| -5.7605136| -6.134823| -6.383234|\n|  2| -5.2395048| -5.913262| -6.360401|\n|  3| -4.4924729| -5.465678| -6.111546|\n|  4| -3.9815814| -5.254234| -6.098831|\n|  5| -3.2842725| -4.856372| -5.899698|\n|  6| -2.5186269| -4.390174| -5.632228|\n|  7| -1.8436706| -4.014666| -5.455448|\n|  8| -1.3186498| -3.789093| -5.428604|\n|  9| -0.8059345| -3.575825| -5.414065|\n| 10| -0.1827594| -3.252097| -5.289066|\n:::\n:::\n\nsuggesting that we should us $p=1$ as the AIC is minimized for that choice. The table below shows the resulting coefficients when re-running the VAR estimation through least-squares with differenced data and the proposed, optimal lag-length. \n\n::: {.cell fig.dim=\"[7,4]\"}\n\n```\n#> \n#> \n#> |from     |to   |   estimate|        se|    t_value|   p_value|signif |      upper|      lower|\n#> |:--------|:----|----------:|---------:|----------:|---------:|:------|----------:|----------:|\n#> |constant |e    |  0.2083477| 0.1124489|  1.8528210| 0.0682478|.      |  0.4327360| -0.0160406|\n#> |e_l1     |e    |  0.9808516| 0.1685209|  5.8203552| 0.0000002|***    |  1.3171298|  0.6445733|\n#> |prod_l1  |e    |  0.1678098| 0.0674589|  2.4875839| 0.0153187|*      |  0.3024220|  0.0331976|\n#> |rw_l1    |e    | -0.0289441| 0.0524059| -0.5523049| 0.5825503|       |  0.0756304| -0.1335185|\n#> |U_l1     |e    |  0.2044321| 0.2133321|  0.9582811| 0.3413158|       |  0.6301297| -0.2212654|\n#> |e_l2     |e    | -0.3753555| 0.1902234| -1.9732355| 0.0525348|.      |  0.0042293| -0.7549403|\n#> |prod_l2  |e    |  0.0365697| 0.0701825|  0.5210653| 0.6040141|       |  0.1766168| -0.1034774|\n#> |rw_l2    |e    | -0.0377565| 0.0495803| -0.7615231| 0.4489777|       |  0.0611794| -0.1366925|\n#> |U_l2     |e    | -0.0261252| 0.2102120| -0.1242801| 0.9014602|       |  0.3933463| -0.4455966|\n#> |e_l3     |e    |  0.1325813| 0.1809185|  0.7328232| 0.4661849|       |  0.4935985| -0.2284360|\n#> |prod_l3  |e    |  0.0356916| 0.0686266|  0.5200839| 0.6046942|       |  0.1726339| -0.1012507|\n#> |rw_l3    |e    | -0.0689978| 0.0514926| -1.3399543| 0.1847208|       |  0.0337542| -0.1717498|\n#> |U_l3     |e    |  0.2181991| 0.2100341|  1.0388743| 0.3025432|       |  0.6373157| -0.2009175|\n#> |constant |prod |  0.4910228| 0.1980128|  2.4797524| 0.0156300|*      |  0.8861512|  0.0958943|\n#> |e_l1     |prod | -0.1983424| 0.2967508| -0.6683803| 0.5061534|       |  0.3938146| -0.7904994|\n#> |prod_l1  |prod |  0.1777616| 0.1187894|  1.4964434| 0.1391654|       |  0.4148021| -0.0592789|\n#> |rw_l1    |prod |  0.0762154| 0.0922823|  0.8258936| 0.4117527|       |  0.2603620| -0.1079312|\n#> |U_l1     |prod | -0.8210385| 0.3756594| -2.1855930| 0.0322930|*      | -0.0714219| -1.5706552|\n#> |e_l2     |prod | -0.3446581| 0.3349670| -1.0289315| 0.3071579|       |  0.3237581| -1.0130742|\n#> |prod_l2  |prod |  0.0042470| 0.1235854|  0.0343649| 0.9726869|       |  0.2508578| -0.2423638|\n#> |rw_l2    |prod | -0.1602645| 0.0873066| -1.8356510| 0.0707820|.      |  0.0139532| -0.3344822|\n#> |U_l2     |prod | -0.1201730| 0.3701652| -0.3246470| 0.7464449|       |  0.6184801| -0.8588261|\n#> |e_l3     |prod |  0.0050195| 0.3185819|  0.0157559| 0.9874753|       |  0.6407398| -0.6307007|\n#> |prod_l3  |prod |  0.0627097| 0.1208456|  0.5189242| 0.6054984|       |  0.3038533| -0.1784339|\n#> |rw_l3    |prod | -0.0727783| 0.0906741| -0.8026358| 0.4249817|       |  0.1081591| -0.2537156|\n#> |U_l3     |prod |  0.3896526| 0.3698520|  1.0535365| 0.2958244|       |  1.1276807| -0.3483756|\n#> |constant |rw   |  0.5147553| 0.2702007|  1.9050850| 0.0609988|.      |  1.0539323| -0.0244218|\n#> |e_l1     |rw   | -0.0782530| 0.4049347| -0.1932483| 0.8473405|       |  0.7297817| -0.8862876|\n#> |prod_l1  |rw   | -0.1775299| 0.1620954| -1.0952188| 0.2772848|       |  0.1459264| -0.5009863|\n#> |rw_l1    |rw   |  0.2351661| 0.1259249|  1.8675099| 0.0661408|.      |  0.4864454| -0.0161132|\n#> |U_l1     |rw   |  0.4421155| 0.5126103|  0.8624788| 0.3914557|       |  1.4650136| -0.5807825|\n#> |e_l2     |rw   |  0.4802272| 0.4570830|  1.0506346| 0.2971460|       |  1.3923222| -0.4318677|\n#> |prod_l2  |rw   | -0.4205755| 0.1686399| -2.4939267| 0.0150707|*      | -0.0840599| -0.7570912|\n#> |rw_l2    |rw   |  0.1102996| 0.1191353|  0.9258350| 0.3578060|       |  0.3480303| -0.1274311|\n#> |U_l2     |rw   | -0.0280260| 0.5051131| -0.0554846| 0.9559151|       |  0.9799115| -1.0359635|\n#> |e_l3     |rw   | -0.0061182| 0.4347246| -0.0140737| 0.9888124|       |  0.8613612| -0.8735975|\n#> |prod_l3  |rw   |  0.0159873| 0.1649012|  0.0969508| 0.9230507|       |  0.3450426| -0.3130680|\n#> |rw_l3    |rw   |  0.0503535| 0.1237304|  0.4069612| 0.6853147|       |  0.2972536| -0.1965467|\n#> |U_l3     |rw   | -0.1616087| 0.5046858| -0.3202165| 0.7497861|       |  0.8454761| -1.1686935|\n#> |constant |U    |  0.0621652| 0.0881933|  0.7048743| 0.4832958|       |  0.2381522| -0.1138218|\n#> |e_l1     |U    | -0.6056371| 0.1321704| -4.5822452| 0.0000202|***    | -0.3418952| -0.8693790|\n#> |prod_l1  |U    | -0.1293133| 0.0529078| -2.4441239| 0.0171191|*      | -0.0237374| -0.2348892|\n#> |rw_l1    |U    |  0.0304879| 0.0411018|  0.7417652| 0.4607839|       |  0.1125053| -0.0515295|\n#> |U_l1     |U    | -0.2409259| 0.1673156| -1.4399485| 0.1544701|       |  0.0929473| -0.5747991|\n#> |e_l2     |U    | -0.0207449| 0.1491916| -0.1390491| 0.8898224|       |  0.2769622| -0.3184521|\n#> |prod_l2  |U    | -0.0360882| 0.0550439| -0.6556253| 0.5142774|       |  0.0737503| -0.1459267|\n#> |rw_l2    |U    |  0.0978808| 0.0388857|  2.5171432| 0.0141935|*      |  0.1754759|  0.0202856|\n#> |U_l2     |U    | -0.2519655| 0.1648685| -1.5282809| 0.1310814|       |  0.0770246| -0.5809555|\n#> |e_l3     |U    | -0.0218685| 0.1418938| -0.1541188| 0.8779725|       |  0.2612761| -0.3050131|\n#> |prod_l3  |U    | -0.0372050| 0.0538236| -0.6912395| 0.4917682|       |  0.0701984| -0.1446084|\n#> |rw_l3    |U    |  0.0728203| 0.0403855|  1.8031291| 0.0757984|.      |  0.1534083| -0.0077677|\n#> |U_l3     |U    | -0.1562538| 0.1647291| -0.9485503| 0.3462083|       |  0.1724579| -0.4849656|\n```\n:::\n\nWe can also ...\n\n::: {.cell fig.dim=\"[7,4]\"}\n::: {.cell-output-display}\n![](VARs_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n### Prediction\n\n::: {.cell}\n\n:::\n\nOnce the VAR has been fitted, it can be used for prediction. \n\n... Maths to follow\n\nIn R, we can predict from a model that has been estimated through `VAR` using the `VAR_predict` function. The figure below shows the 10-step ahead predictions for our model. \n\n::: {.cell fig.dim=\"[7,4]\"}\n::: {.cell-output-display}\n![10-step ahead predictions from estimated VAR.](VARs_files/figure-html/predict-1.png){width=672}\n:::\n:::",
    "supporting": [
      "VARs_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}